{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8KrrzNGd8KCX",
        "G7s_-PkZvFLS",
        "TNCjxtUT8Pcf",
        "CUDbmmBX8Vih",
        "tD2s1mpvD5f8",
        "xk_fdc7PkyoN"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCI8UwvjIP_J"
      },
      "source": [
        "!pip install pydub\n",
        "!pip install tensorflow-io\n",
        "!pip install mutagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJRSZDQuBLS5"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import shutil\n",
        "import mutagen\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display\n",
        "from pydub import AudioSegment\n",
        "from mutagen.wave import WAVE\n",
        "from string import ascii_lowercase"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KrrzNGd8KCX"
      },
      "source": [
        "### GetCleanFile Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewBM_6fcbFuq"
      },
      "source": [
        "class GetCleanFile:\n",
        "  def __init__(self, origin, new_path, newer_path):\n",
        "    self.origin = origin\n",
        "    self.new_path = new_path\n",
        "    self.newer_path = newer_path\n",
        "    self.train_path = \"\"\n",
        "    \n",
        "    # make new directory to contain organized sub-directory\n",
        "    if not os.path.exists(self.newer_path):\n",
        "      os.mkdir(self.newer_path)\n",
        "  \n",
        "  def __call__(self):\n",
        "    # download data from the web server\n",
        "    data_dir = pathlib.Path(self.new_path)\n",
        "    \n",
        "    if not data_dir.exists():\n",
        "      tf.keras.utils.get_file(\n",
        "          'librispeech.zip',\n",
        "          origin = self.origin,\n",
        "          extract = True,\n",
        "          cache_dir = '.',\n",
        "          cache_subdir = self.new_path.split('/')[-1])\n",
        "      \n",
        "    return self\n",
        "  \n",
        "  def get_train_path (self):\n",
        "    '''get train data directory path'''\n",
        "    all_file = os.listdir(self.new_path)\n",
        "    dir = [i for i in all_file if not re.match('[\\w]*.zip',i)][0]\n",
        "    path = os.path.join(new_path,dir)\n",
        "    train_dir = [i for i in os.listdir(path) if not re.match('[\\w]*.TXT',i)][0]\n",
        "    self.train_path = os.path.join(path,train_dir)\n",
        "    return self\n",
        "\n",
        "  def get_subdirectory(self):\n",
        "    '''including subdirectories and excluding upper directories'''\n",
        "    return tf.io.gfile.glob(str(self.train_path)+'/*/*')\n",
        "\n",
        "  def rename_and_move_dir(self, dir_names):\n",
        "    ''' rename the sub-directory and move the subdirectory\n",
        "        to another directory'''\n",
        "    for i, dir in enumerate(dir_names):\n",
        "        split_dir = dir.split('/')\n",
        "        split_dir[-1] = str(i)\n",
        "        joined_dir = '/'.join(split_dir)\n",
        "        shutil.move(dir, joined_dir)\n",
        "        shutil.move(joined_dir, self.newer_path)\n",
        "    return self\n",
        "  \n",
        "  def delete_directory(self):\n",
        "    '''delete initial data directory'''\n",
        "    shutil.rmtree(self.new_path)\n",
        "\n",
        "  def clean_label(self, subdirs):\n",
        "    '''process the label so its content does not have filename in front of each\n",
        "        lines'''\n",
        "    for subdir in subdirs:\n",
        "      # Define sub-directory for the new files\n",
        "      new_subdir = subdir.split('/')[:-1]\n",
        "      new_subdir = '/'.join(new_subdir)\n",
        "\n",
        "      with open(subdir, 'r') as f:\n",
        "      \n",
        "        # Read all lines and return as list\n",
        "        lines = f.readlines()\n",
        "\n",
        "        # iterate line by line\n",
        "        for line in lines:\n",
        "          new_name = line.split()[0]\n",
        "          content = ' '.join(line.split()[1:]).lower()\n",
        "          file_subdir = os.path.join(new_subdir, f'{new_name}.txt')\n",
        "          with open(file_subdir, 'w') as new_file:\n",
        "            new_file.write(content)\n",
        "\n",
        "        # delete initial text file\n",
        "        os.remove(subdir)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7s_-PkZvFLS"
      },
      "source": [
        "### EncodingDecoding Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb6DOUzMvmj7"
      },
      "source": [
        "class EncodingDecoding:\n",
        "  def __init__(self):\n",
        "    self.char = [c for c in ascii_lowercase]\n",
        "    self.non_alpha = [\" \", \"'\"]\n",
        "    self.non_alpha.extend(self.char)  \n",
        "\n",
        "  def encode_label(self, label):\n",
        "    keys_tensor = tf.constant(self.non_alpha)\n",
        "    vals_tensor = tf.constant(np.arange(len(self.non_alpha)))\n",
        "    input_tensor = label\n",
        "\n",
        "    table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n",
        "        default_value=-1)\n",
        "    \n",
        "    return table.lookup(input_tensor)\n",
        "\n",
        "  def decode_label(self,predicted_label):\n",
        "    keys_tensor = tf.constant(np.arange(len(self.non_alpha)))\n",
        "    vals_tensor = tf.constant(self.non_alpha)\n",
        "    input_tensor = predicted_label\n",
        "\n",
        "    table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n",
        "        default_value='')\n",
        "    \n",
        "    return table.lookup(input_tensor).numpy()\n",
        "  \n",
        "  def decode_audio(self, audio_binary):\n",
        "    ''' decode wav file to float tensor'''\n",
        "    waveform, _ = tf.audio.decode_wav(audio_binary)\n",
        "    return tf.squeeze(waveform,axis=-1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNCjxtUT8Pcf"
      },
      "source": [
        "### AudioFileConversion Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fua0IT4c1IeN"
      },
      "source": [
        "class AudioFileConversion:\n",
        "  def convert_flac_to_wav(self, src, dst):\n",
        "    flac_audio = AudioSegment.from_file(src,format=\"flac\")\n",
        "    flac_audio.export(dst, format=\"wav\") \n",
        "\n",
        "  def file_conversion(self, path):\n",
        "    '''convert flac file into wav file'''\n",
        "    for i, (subdirs, dir, fnames) in enumerate(os.walk(path)):\n",
        "      if i > 0: \n",
        "        fnames = [fname for fname in fnames if not re.match('[\\w\\d.-]*.txt',fname)]\n",
        "        for fname in fnames:\n",
        "\n",
        "          # creating source path and destination path for the converted file\n",
        "          src = os.path.join(subdirs,fname)\n",
        "          fname_split = fname.split('.')\n",
        "          fname_split[-1]='wav'\n",
        "          fname = '.'.join(fname_split)\n",
        "          dst =  os.path.join(subdirs, fname)\n",
        "\n",
        "          # convert flac file format into wav file format\n",
        "          self.convert_flac_to_wav(src, dst)\n",
        "\n",
        "          # delete initial flac file\n",
        "          os.remove(src) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUDbmmBX8Vih"
      },
      "source": [
        "### AudioDataProcessing Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE6KSIBkfy3Y"
      },
      "source": [
        "class AudioDataProcessing:\n",
        "  def __init__(self, path):\n",
        "    self.path = path\n",
        "    self.max_length = 0\n",
        "    self.sample_rate = 16000\n",
        "  def get_max_length(self):\n",
        "    '''find maximum length file'''\n",
        "    audio_length = []\n",
        "    file_dir = tf.io.gfile.glob(self.path+'/*/*.wav')\n",
        "    for fil in file_dir:\n",
        "      audio = WAVE(fil).info.length\n",
        "      audio_length.append(audio)\n",
        "    self.max_length = max(audio_length)\n",
        "\n",
        "    return self\n",
        "\n",
        "  def get_spectrogram(self, waveform):\n",
        "    '''Create spectogram from audio wave form'''\n",
        "    # Padding for files with less than max sample\n",
        "    max_sample = int(self.max_length * self.sample_rate)\n",
        "    zero_padding = tf.zeros([max_sample] - tf.shape(waveform), dtype=tf.float32)\n",
        "\n",
        "    # Concatenate audio with padding so that all audio clips will be of the \n",
        "    # same length\n",
        "    waveform = tf.cast(waveform, tf.float32)\n",
        "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
        "    spectrogram = tf.signal.stft(\n",
        "        equal_length, frame_length=1024, \n",
        "        frame_step = 892)\n",
        "      \n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "    #Spoken Word Recognition Using MFCC and Learning Vector Quantization\n",
        "  def get_log_mel_spectrograms(self, spectrogram):\n",
        "    '''extract log mel spectrogram from spectrogram'''\n",
        "    num_spectrogram_bins = spectrogram.shape[-1]\n",
        "    num_mel_bins, lower_edge_hertz, upper_edge_hertz = 13, 250, 8000\n",
        "    weight = tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins,\n",
        "                                                 self.sample_rate, lower_edge_hertz,\n",
        "                                                 upper_edge_hertz)\n",
        "    mel_spectrograms = tf.tensordot(spectrogram,weight,1)\n",
        "    mel_spectrograms.set_shape(spectrogram.shape[:-1].concatenate(\n",
        "            weight.shape[-1:]))\n",
        "  \n",
        "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
        "    return log_mel_spectrograms\n",
        "  \n",
        "  def get_mfcc(self, log_mel_spectrograms):\n",
        "    '''extract mel frequency ceptrums coefficients from audio waveform'''\n",
        "    mfcc = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)\n",
        "    return mfcc\n",
        "\n",
        "  def spec_augment(self):\n",
        "    '''perform data augmentation for audio log spectrogram'''\n",
        "    param = np.random.randint(1,100)\n",
        "    augmentation = tf.keras.Sequential([\n",
        "       layers.Lambda(lambda x : tfio.experimental.audio.freq_mask(x, param)),\n",
        "       layers.Lambda(lambda x : tfio.experimental.audio.time_mask(x, param))            \n",
        "    ])\n",
        "\n",
        "    return augmentation"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD2s1mpvD5f8"
      },
      "source": [
        "### GetWaveformLabel Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6sksXMP-M2v"
      },
      "source": [
        "class GetWaveformLabel(EncodingDecoding):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def get_waveform_label(self, audio_file, text_file):\n",
        "    # decode WAV audio file\n",
        "    audio_data = tf.io.read_file(audio_file)\n",
        "    waveform = super().decode_audio(audio_data)\n",
        "    \n",
        "    #convert tensor into str\n",
        "    text = tf.io.read_file(text_file)\n",
        "\n",
        "    #split char from whole string\n",
        "    chars = tf.strings.bytes_split(text)\n",
        "\n",
        "    # encode text file to numeric values  \n",
        "    label = super().encode_label(chars)\n",
        "\n",
        "    return waveform, label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk_fdc7PkyoN"
      },
      "source": [
        "### GetProcessDataLabel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt2ggNcgjIFO"
      },
      "source": [
        "class GetProcessDataLabel(AudioDataProcessing):\n",
        "  def __init__(self, path):\n",
        "    super().__init__(path)\n",
        "  \n",
        "  def get_process_label(self, waveform, label):\n",
        "    super().get_max_length()\n",
        "    x = super().get_spectrogram(waveform)\n",
        "    x = super().spec_augment()(x)\n",
        "    x = super().get_log_mel_spectrograms(x)\n",
        "    x = super().get_mfcc(x)\n",
        "    return x, label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mBVv4038co1"
      },
      "source": [
        "### Extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSDFAddr8Ad0"
      },
      "source": [
        "def organize_file(origin, new_path, newer_path):\n",
        "  get_clean_file = GetCleanFile(origin,new_path,newer_path)\n",
        "  dir_names = get_clean_file().get_train_path().get_subdirectory()\n",
        "  get_clean_file.rename_and_move_dir(dir_names)\n",
        "  get_clean_file.delete_directory()\n",
        "\n",
        "  subdir = tf.io.gfile.glob(newer_path + '/*/*.txt')\n",
        "  subdir_1 = tf.io.gfile.glob(newer_path + '/*/*.flac')\n",
        "  get_clean_file.clean_label(subdir)\n",
        "\n",
        "def flac_conversion(path):\n",
        "  file_conversion = AudioFileConversion()\n",
        "  file_conversion.file_conversion(path)\n",
        "\n",
        "def preprocess_dataset(path):\n",
        "  newer_path = './DATA'\n",
        "  AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "  audio_file = sorted(np.array(tf.io.gfile.glob(str(newer_path) + '/*/*.wav')))\n",
        "  text_file = sorted(np.array(tf.io.gfile.glob(str(newer_path) + '/*/*.txt')))\n",
        "  list_ds = tf.data.Dataset.from_tensor_slices((audio_file, text_file)).cache()\n",
        "  \n",
        "  get_waveform_label = GetWaveformLabel()\n",
        "  get_process_data_label = GetProcessDataLabel('./DATA').get_max_length()\n",
        "  \n",
        "  waveform_ds = list_ds.map(get_waveform_label.get_waveform_label, num_parallel_calls=AUTOTUNE)\n",
        "  waveform_ds = waveform_ds.cache()\n",
        "  waveform_ds = waveform_ds.prefetch(AUTOTUNE)\n",
        "\n",
        "  spectrogram_ds = waveform_ds.map(get_process_data_label.get_process_label, num_parallel_calls=AUTOTUNE)\n",
        "  spectrogram_ds = spectrogram_ds.cache()\n",
        "\n",
        "  preprocess_ds = spectrogram_ds.shuffle(1024).repeat(5).batch(128)\n",
        "  return preprocess_ds\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "w_pQH3jPGomF",
        "outputId": "cf51e8e2-eb9d-4fb4-8405-38b25384afd4"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "  origin = 'https://www.openslr.org/resources/12/train-clean-100.tar.gz'\n",
        "  new_path = './data'\n",
        "  newer_path = './DATA'\n",
        "  organize_file(origin, new_path, newer_path)\n",
        "  flac_conversion(newer_path)\n",
        "  preprocess_ds = preprocess_dataset(newer_path)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "6387310592/6387309499 [==============================] - 221s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b4a27ffbca6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0morganize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mflac_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpreprocess_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-777433327460>\u001b[0m in \u001b[0;36mpreprocess_dataset\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mwaveform_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveform_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mspectrogram_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveform_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_process_data_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mspectrogram_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrogram_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1930\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4525\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4526\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4528\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \"\"\"\n\u001b[1;32m   3134\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3135\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3686\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3687\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3617\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-8-0562378d4440>:8 get_process_label  *\n        x = super().spec_augment()(x)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:919 call\n        result = self.function(inputs, **kwargs)\n    /tmp/tmpk5_vnao_.py:12 <lambda>\n        augmentation = ag__.converted_call(ag__.ld(tf).keras.Sequential, ([ag__.converted_call(ag__.ld(layers).Lambda, (ag__.autograph_artifact((lambda x: ag__.converted_call(ag__.ld(tfio).experimental.audio.freq_mask, (ag__.ld(x), ag__.ld(param)), None, fscope))),), None, fscope), ag__.converted_call(ag__.ld(layers).Lambda, (ag__.autograph_artifact((lambda x: ag__.converted_call(ag__.ld(tfio).experimental.audio.time_mask, (ag__.ld(x), ag__.ld(param)), None, fscope))),), None, fscope)],), None, fscope)\n\n    AttributeError: module 'tensorflow_io.core.python.api.experimental' has no attribute 'audio'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL5VJm0WzCOD"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h7uF4Ayn2fJ"
      },
      "source": [
        "display.Audio(waveform.numpy(),rate=sample_rate.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAZACst0q8ba"
      },
      "source": [
        "def plot_spectrogram(spectrogram, ax):\n",
        "  # Convert to frequencies to log scale and transpose so that the time is\n",
        "  # represented in the x-axis (columns).\n",
        "  log_spec = np.log(spectrogram.T)\n",
        "  height = log_spec.shape[0]\n",
        "  width = log_spec.shape[1]\n",
        "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
        "  Y = range(height)\n",
        "  ax.pcolormesh(X, Y, log_spec)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
        "timescale = np.arange(waveform.shape[0])\n",
        "axes[0].plot(timescale, waveform.numpy())\n",
        "axes[0].set_title('Waveform')\n",
        "\n",
        "result = audio_processing.spec_augment()(spectrogram)\n",
        "plot_spectrogram(result.numpy(), axes[1])\n",
        "axes[1].set_title('Spectrogram')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYdUTayVy_Il"
      },
      "source": [
        "#build network model using Keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(16000,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['acc'])\n",
        "model.fit(waveform, label, batch_size=124, epochs=20, verbose=1, validation_data=(,))\n",
        "print('Loss for test: ', sc[0])\n",
        "print('Accuracy: ', sc[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}